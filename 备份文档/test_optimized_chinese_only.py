#!/usr/bin/env python3
"""
æµ‹è¯•ä¼˜åŒ–åçš„"ä»…ä¸­æ–‡ç‰ˆæœ¬"åŠŸèƒ½ - ç›´æ¥è®¿é—®ç¿»è¯‘é¡µé¢
"""

import sys
import os
from pathlib import Path
from bs4 import BeautifulSoup
import requests

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def test_optimized_chinese_only():
    """æµ‹è¯•ä¼˜åŒ–åçš„ä¸­æ–‡ç‰ˆæœ¬ä¸‹è½½åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•ä¼˜åŒ–åçš„'ä»…ä¸­æ–‡ç‰ˆæœ¬'åŠŸèƒ½...")
    print("=" * 60)

    try:
        # è¯»å–Cookie
        with open('extracted_cookies.txt', 'r', encoding='utf-8') as f:
            cookie_string = f.read().strip()

        # è§£æCookie
        cookies = {}
        for item in cookie_string.split(';'):
            if '=' in item:
                key, value = item.strip().split('=', 1)
                cookies[key] = value

        # åˆ›å»ºsession
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })
        session.cookies.update(cookies)

        # æ¨¡æ‹Ÿä¼˜åŒ–åçš„ç›´æ¥ç¿»è¯‘é¡µé¢è§£æé€»è¾‘
        print(f"ğŸ¯ æ¨¡æ‹Ÿé€‰æ‹©'ä»…ä¸­æ–‡ç‰ˆæœ¬'ï¼Œç›´æ¥è®¿é—®ç¿»è¯‘é¡µé¢...")

        # ç›´æ¥è®¿é—®ç¿»è¯‘é¡µé¢
        translation_url = "https://www.nccn.org/global/what-we-do/guidelines-for-patients-translations"
        print(f"ğŸŒ ç›´æ¥è®¿é—®ç¿»è¯‘é¡µé¢: {translation_url}")

        response = session.get(translation_url)
        print(f"ğŸ“¡ çŠ¶æ€ç : {response.status_code}")

        if response.status_code != 200:
            print("âŒ ç¿»è¯‘é¡µé¢è®¿é—®å¤±è´¥")
            return False

        translation_soup = BeautifulSoup(response.content, 'html.parser')

        # æŸ¥æ‰¾Chinese Translationséƒ¨åˆ†
        print(f"ğŸ” æŸ¥æ‰¾Chinese Translationséƒ¨åˆ†...")
        chinese_headers = translation_soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])

        chinese_section = None
        for header in chinese_headers:
            if 'Chinese' in header.get_text():
                chinese_section = header
                print(f"âœ… æ‰¾åˆ°Chinese Translationséƒ¨åˆ†: {header.get_text(strip=True)}")
                break

        if not chinese_section:
            print("âŒ æœªæ‰¾åˆ°Chinese Translationséƒ¨åˆ†")
            return False

        # ä»Chinese Translationséƒ¨åˆ†å¼€å§‹æŸ¥æ‰¾PDFé“¾æ¥
        current = chinese_section
        processed_sections = 0
        chinese_pdfs = []

        # éå†Chinese Translationsåé¢çš„æ‰€æœ‰å…ƒç´ ï¼Œç›´åˆ°ä¸‹ä¸€ä¸ªè¯­è¨€æ ‡é¢˜
        while current and processed_sections < 50:
            current = current.find_next_sibling()

            if current is None:
                break

            if current.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:  # é‡åˆ°ä¸‹ä¸€ä¸ªè¯­è¨€éƒ¨åˆ†ï¼Œåœæ­¢
                print(f"ğŸ›‘ é‡åˆ°ä¸‹ä¸€ä¸ªè¯­è¨€éƒ¨åˆ†ï¼Œåœæ­¢è§£æ")
                break

            # æŸ¥æ‰¾å½“å‰å…ƒç´ ä¸­çš„æ‰€æœ‰é“¾æ¥
            links = current.find_all('a', href=True)

            for link in links:
                href = link.get('href', '')
                link_text = link.get_text(strip=True)

                # æŸ¥æ‰¾PDFé“¾æ¥
                if '/patients/guidelines/content/PDF/' in href and href.endswith('.pdf'):
                    # æ­£ç¡®æ‹¼æ¥URL
                    if href.startswith('http'):
                        pdf_url = href
                    else:
                        pdf_url = 'https://www.nccn.org' + href

                    # ç¡®å®šæ ‡é¢˜
                    title = link_text if link_text else 'Chinese Patient Guideline'
                    if not title:
                        filename = href.split('/')[-1].replace('.pdf', '')
                        title = filename.replace('-zh', '').replace('-', ' ') + ' (Chinese)'

                    chinese_pdfs.append({
                        'title': title,
                        'url': pdf_url,
                        'href': href
                    })

                    print(f"ğŸ‡¨ğŸ‡³ ç¿»è¯‘é¡µPDF: {title} -> {href}")

            processed_sections += 1

        print(f"\nğŸ“Š ä¼˜åŒ–å'ä»…ä¸­æ–‡ç‰ˆæœ¬'è§£æç»“æœ:")
        print(f"   è§£ææ–¹å¼: ç›´æ¥è®¿é—®ç¿»è¯‘é¡µé¢ï¼ˆè·³è¿‡ä¸»é¡µæ‰«æï¼‰")
        print(f"   æ‰¾åˆ°ä¸­æ–‡PDFæ•°: {len(chinese_pdfs)}")

        # éªŒè¯ç»“æœ
        if len(chinese_pdfs) >= 10:
            print(f"\nâœ… æµ‹è¯•æˆåŠŸï¼ä¼˜åŒ–åçš„'ä»…ä¸­æ–‡ç‰ˆæœ¬'åŠŸèƒ½æ­£å¸¸")
            print(f"ğŸš€ æ•ˆç‡æå‡ï¼š")
            print(f"   â€¢ è·³è¿‡ä¸»é¡µæ‰«æ")
            print(f"   â€¢ è·³è¿‡è¯¦æƒ…é¡µéå†")
            print(f"   â€¢ ç›´æ¥è®¿é—®ç¿»è¯‘é¡µé¢")
            print(f"   â€¢ è§£æé€Ÿåº¦æ˜¾è‘—æå‡")

            print(f"\nğŸ“‹ æ‰¾åˆ°çš„æ‰€æœ‰ä¸­æ–‡PDF:")
            for i, pdf in enumerate(chinese_pdfs, 1):
                print(f"   {i:2d}. {pdf['title']}")

            return True
        else:
            print(f"\nâš ï¸  æµ‹è¯•å¤±è´¥ï¼Œåªæ‰¾åˆ° {len(chinese_pdfs)} ä¸ªä¸­æ–‡PDF")
            return False

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def simulate_full_workflow_comparison():
    """æ¨¡æ‹Ÿå®Œæ•´å·¥ä½œæµç¨‹å¯¹æ¯”ï¼šä¼˜åŒ–å‰ vs ä¼˜åŒ–å"""
    print(f"\nğŸ“‹ å·¥ä½œæµç¨‹å¯¹æ¯”åˆ†æ:")
    print(f"=" * 60)

    print(f"ğŸ”„ ä¼˜åŒ–å‰æµç¨‹ (é€‰æ‹©'ä»…ä¸­æ–‡ç‰ˆæœ¬'):")
    print(f"   1. æ‰«æä¸»é¡µ â†’ æ‰¾åˆ°65ä¸ªè¯¦æƒ…é¡µé“¾æ¥")
    print(f"   2. éå†è¯¦æƒ…é¡µ â†’ è®¿é—®65ä¸ªè¯¦æƒ…é¡µé¢")
    print(f"   3. æŸ¥æ‰¾ç¿»è¯‘é¡µé¢é“¾æ¥ â†’ æ‰¾åˆ°2ä¸ªç¿»è¯‘é¡µé¢")
    print(f"   4. è®¿é—®ç¿»è¯‘é¡µé¢ â†’ è§£æä¸­æ–‡PDF")
    print(f"   æ€»è¯·æ±‚æ•°: 67+ ä¸ªHTTPè¯·æ±‚")
    print(f"   é¢„è®¡æ—¶é—´: 2-5 åˆ†é’Ÿ")

    print(f"\nâš¡ ä¼˜åŒ–åæµç¨‹ (é€‰æ‹©'ä»…ä¸­æ–‡ç‰ˆæœ¬'):")
    print(f"   1. ç›´æ¥è®¿é—®ç¿»è¯‘é¡µé¢")
    print(f"   2. è§£æChinese Translationséƒ¨åˆ†")
    print(f"   æ€»è¯·æ±‚æ•°: 1 ä¸ªHTTPè¯·æ±‚")
    print(f"   é¢„è®¡æ—¶é—´: 10-30 ç§’")

    print(f"\nğŸ¯ æ•ˆç‡æå‡:")
    print(f"   â€¢ HTTPè¯·æ±‚å‡å°‘: ~66ä¸ª (å‡å°‘98.5%)")
    print(f"   â€¢ è§£ææ—¶é—´å‡å°‘: 90%+")
    print(f"   â€¢ ç½‘ç»œæµé‡å‡å°‘: æ˜¾è‘—å‡å°‘")
    print(f"   â€¢ ç”¨æˆ·ä½“éªŒ: å¤§å¹…æ”¹å–„")

if __name__ == "__main__":
    success = test_optimized_chinese_only()
    simulate_full_workflow_comparison()

    print(f"\n{'='*60}")
    if success:
        print("ğŸ‰ ä¼˜åŒ–éªŒè¯æˆåŠŸï¼")
        print("âœ… ä¼˜åŒ–åçš„'ä»…ä¸­æ–‡ç‰ˆæœ¬'åŠŸèƒ½:")
        print("   â€¢ ç›´æ¥è®¿é—®ç¿»è¯‘é¡µé¢")
        print("   â€¢ è·³è¿‡ä¸»é¡µå’Œè¯¦æƒ…é¡µæ‰«æ")
        print("   â€¢ è§£ææ•ˆç‡æ˜¾è‘—æå‡")
        print("ğŸš€ ç°åœ¨å¯ä»¥æµ‹è¯•ä¸»ç¨‹åºé€‰é¡¹6 â†’ é€‰æ‹©3(ä»…ä¸­æ–‡ç‰ˆæœ¬)")
    else:
        print("âš ï¸  ä¼˜åŒ–éªŒè¯å¤±è´¥")
        print("ğŸ”§ éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")