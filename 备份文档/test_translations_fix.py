#!/usr/bin/env python3
"""
æµ‹è¯•ç¿»è¯‘é¡µé¢è§£æä¿®å¤
"""

import sys
import os
from pathlib import Path
from bs4 import BeautifulSoup
import requests
from urllib.parse import urljoin

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from download_NCCN_Guide_v2_menu import ThemeConfig

class TestTranslationsFix:
    def __init__(self):
        self.session = requests.Session()

        # æ¨¡æ‹ŸThemeConfig
        self.clinical_theme = ThemeConfig(
            category='clinical_translations',
            name='clinical_translations',
            display_name='ä¸´åºŠæŒ‡å—ä¸­æ–‡ç¿»è¯‘ (Clinical Translations)',
            url='https://www.nccn.org/global/what-we-do/clinical-guidelines-translations',
            description='ä¸´åºŠæŒ‡å—ä¸­æ–‡ç¿»è¯‘ç‰ˆæœ¬',
            directory='04_Clinical_Translations'
        )

        self.patient_theme = ThemeConfig(
            category='patient_translations',
            name='patient_translations',
            display_name='æ‚£è€…æŒ‡å—ä¸­æ–‡ç¿»è¯‘ (Patient Guidelines Translations)',
            url='https://www.nccn.org/global/what-we-do/guidelines-for-patients-translations',
            description='æ‚£è€…æŒ‡å—ä¸­æ–‡ç¿»è¯‘ç‰ˆæœ¬',
            directory='05_Patient_Translations'
        )

    def test_parse_translations(self, theme):
        """æµ‹è¯•ç¿»è¯‘é¡µé¢è§£æ"""
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•ä¸»é¢˜: {theme.display_name}")
        print(f"URL: {theme.url}")
        print(f"{'='*60}")

        try:
            # è·å–é¡µé¢å†…å®¹
            response = self.session.get(theme.url, timeout=30)
            response.raise_for_status()

            print(f"âœ… HTTPè¯·æ±‚æˆåŠŸï¼ŒçŠ¶æ€ç : {response.status_code}")
            print(f"ğŸ“„ é¡µé¢å†…å®¹é•¿åº¦: {len(response.content)} å­—èŠ‚")

            soup = BeautifulSoup(response.content, 'html.parser')

            # ä½¿ç”¨ä¿®å¤åçš„è§£ææ–¹æ³•
            pdf_links = self._parse_translations(soup, theme)

            print(f"\nğŸ“Š è§£æç»“æœ:")
            print(f"   - æ‰¾åˆ°PDFé“¾æ¥æ•°: {len(pdf_links)}")

            if pdf_links:
                print(f"\nğŸ“‹ å‰10ä¸ªPDFé“¾æ¥ç¤ºä¾‹:")
                for i, pdf in enumerate(pdf_links[:10], 1):
                    print(f"   {i:2d}. {pdf['title'][:50]}...")
                    print(f"       URL: {pdf['url'][:80]}...")
            else:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•PDFé“¾æ¥ï¼")

            return pdf_links

        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return []

    def _parse_translations(self, soup: BeautifulSoup, theme) -> list:
        """ä¿®å¤åçš„ç¿»è¯‘é¡µé¢è§£ææ–¹æ³•"""
        pdf_links = []

        print(f"ğŸ” å¼€å§‹è§£æç¿»è¯‘é¡µé¢PDFé“¾æ¥...")

        # ç›´æ¥æŸ¥æ‰¾æ‰€æœ‰PDFé“¾æ¥ï¼Œä¸é™åˆ¶åœ¨ç‰¹å®šsectionä¸­
        all_links = soup.find_all('a', href=True)
        pdf_count = 0

        for link in all_links:
            href = link.get('href', '')
            if href.endswith('.pdf'):
                pdf_count += 1

                # æ­£ç¡®æ‹¼æ¥URL - ä½¿ç”¨NCCNæ ¹åŸŸå
                if href.startswith('http'):
                    pdf_url = href
                else:
                    base_url = 'https://www.nccn.org'
                    if href.startswith('/'):
                        pdf_url = base_url + href
                    else:
                        pdf_url = urljoin(base_url, href)

                title = link.text.strip()
                if not title:
                    title = href.split('/')[-1].split('.')[0]

                pdf_links.append({
                    'title': title,
                    'url': pdf_url,
                    'version': 'Chinese',
                    'directory': theme.directory
                })

                if pdf_count <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"ğŸ“„ æ‰¾åˆ°PDF: {title} -> {pdf_url[:80]}...")

        print(f"âœ… ç¿»è¯‘é¡µé¢è§£æå®Œæˆï¼Œå…±æ‰¾åˆ° {pdf_count} ä¸ªPDFé“¾æ¥")
        return pdf_links

def main():
    print("ğŸš€ NCCNç¿»è¯‘é¡µé¢è§£æä¿®å¤æµ‹è¯•")
    print("æµ‹è¯•ä¿®å¤æ•ˆæœï¼šç¡®ä¿ç±»åˆ«4å’Œ5èƒ½æ­£ç¡®è§£æPDFé“¾æ¥")

    tester = TestTranslationsFix()

    # æµ‹è¯•ä¸´åºŠæŒ‡å—ä¸­æ–‡ç¿»è¯‘ (ç±»åˆ«4)
    print("\nğŸ“ æµ‹è¯•ç±»åˆ«4: ä¸´åºŠæŒ‡å—ä¸­æ–‡ç¿»è¯‘")
    clinical_results = tester.test_parse_translations(tester.clinical_theme)

    # æµ‹è¯•æ‚£è€…æŒ‡å—ä¸­æ–‡ç¿»è¯‘ (ç±»åˆ«5)
    print("\nğŸ“ æµ‹è¯•ç±»åˆ«5: æ‚£è€…æŒ‡å—ä¸­æ–‡ç¿»è¯‘")
    patient_results = tester.test_parse_translations(tester.patient_theme)

    # æ€»ç»“æµ‹è¯•ç»“æœ
    print(f"\n{'='*60}")
    print(f"ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
    print(f"{'='*60}")
    print(f"ç±»åˆ«4 (ä¸´åºŠæŒ‡å—ä¸­æ–‡ç¿»è¯‘): {len(clinical_results)} ä¸ªPDFé“¾æ¥")
    print(f"ç±»åˆ«5 (æ‚£è€…æŒ‡å—ä¸­æ–‡ç¿»è¯‘): {len(patient_results)} ä¸ªPDFé“¾æ¥")

    if len(clinical_results) > 0 and len(patient_results) > 0:
        print(f"\nâœ… ä¿®å¤æˆåŠŸï¼ç±»åˆ«4å’Œ5ç°åœ¨éƒ½èƒ½æ­£ç¡®æå–PDFé“¾æ¥")
        print(f"ğŸ”§ ä¿®å¤å†…å®¹:")
        print(f"   - ä¿®æ­£äº†æ–¹æ³•è°ƒç”¨ (_parse_translations)")
        print(f"   - é‡å†™äº†ç¿»è¯‘é¡µé¢è§£æé€»è¾‘")
        print(f"   - ç»Ÿä¸€äº†URLæ‹¼æ¥å¤„ç†")
    else:
        print(f"\nâŒ ä¿®å¤å¯èƒ½æœªå®Œå…¨æˆåŠŸï¼Œè¯·æ£€æŸ¥")

    return len(clinical_results) > 0 and len(patient_results) > 0

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)