#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®å¤åçš„ç¿»è¯‘é¡µé¢è§£æé€»è¾‘
"""

import sys
import os
from pathlib import Path
from bs4 import BeautifulSoup
import requests

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def test_translation_page_parsing():
    """æµ‹è¯•ç¿»è¯‘é¡µé¢è§£æé€»è¾‘"""
    print("ğŸ§ª æµ‹è¯•ä¿®å¤åçš„ç¿»è¯‘é¡µé¢è§£æé€»è¾‘...")
    print("=" * 60)

    try:
        # è¯»å–Cookie
        with open('extracted_cookies.txt', 'r', encoding='utf-8') as f:
            cookie_string = f.read().strip()

        # è§£æCookie
        cookies = {}
        for item in cookie_string.split(';'):
            if '=' in item:
                key, value = item.strip().split('=', 1)
                cookies[key] = value

        # åˆ›å»ºsession
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })
        session.cookies.update(cookies)

        # æµ‹è¯•è®¿é—®ç¿»è¯‘é¡µé¢
        translation_url = "https://www.nccn.org/global/what-we-do/guidelines-for-patients-translations"
        print(f"ğŸŒ è®¿é—®ç¿»è¯‘é¡µé¢: {translation_url}")

        response = session.get(translation_url)
        print(f"ğŸ“¡ çŠ¶æ€ç : {response.status_code}")

        if response.status_code != 200:
            print("âŒ ç¿»è¯‘é¡µé¢è®¿é—®å¤±è´¥")
            return False

        # è§£æHTML
        soup = BeautifulSoup(response.content, 'html.parser')

        # æŸ¥æ‰¾æ‰€æœ‰ä¸­æ–‡PDFé“¾æ¥
        all_links = soup.find_all('a', href=True)
        chinese_pdfs = []

        print(f"\nğŸ” æŸ¥æ‰¾ä¸­æ–‡PDFé“¾æ¥...")
        print(f"ğŸ”— æ€»é“¾æ¥æ•°: {len(all_links)}")

        for link in all_links:
            href = link.get('href', '')
            text = link.get_text(strip=True)

            # æŸ¥æ‰¾ä¸­æ–‡PDFé“¾æ¥ï¼ˆä½¿ç”¨ä¸ä¸»ç¨‹åºç›¸åŒçš„é€»è¾‘ï¼‰
            if '/patients/guidelines/content/PDF/' in href and href.endswith('.pdf'):
                # ç¡®ä¿æ˜¯ä¸­æ–‡ç‰ˆæœ¬
                is_chinese = False
                if '-zh' in href.lower():
                    is_chinese = True
                elif 'chinese' in text.lower():
                    is_chinese = True

                if is_chinese:
                    # æ­£ç¡®æ‹¼æ¥URL
                    if href.startswith('http'):
                        pdf_url = href
                    else:
                        pdf_url = 'https://www.nccn.org' + href

                    chinese_pdfs.append({
                        'title': text if text else 'Chinese Patient Guideline',
                        'url': pdf_url,
                        'href': href
                    })

        print(f"\nğŸ‡¨ğŸ‡³ æ‰¾åˆ°ä¸­æ–‡PDFé“¾æ¥æ•°é‡: {len(chinese_pdfs)}")

        # æ˜¾ç¤ºå‰20ä¸ªä¸­æ–‡PDF
        for i, pdf in enumerate(chinese_pdfs[:20], 1):
            print(f"   {i:2d}. {pdf['title']}")
            print(f"       URL: {pdf['url'][:80]}...")
            print()

        if len(chinese_pdfs) > 20:
            print(f"   ... è¿˜æœ‰ {len(chinese_pdfs) - 20} ä¸ªæ–‡ä»¶")

        # æµ‹è¯•å‡ ä¸ªPDFé“¾æ¥çš„å¯è®¿é—®æ€§
        print(f"\nğŸ§ª æµ‹è¯•å‰3ä¸ªPDFé“¾æ¥çš„å¯è®¿é—®æ€§...")
        accessible_count = 0

        for i, pdf in enumerate(chinese_pdfs[:3], 1):
            try:
                print(f"ğŸ“„ [{i}/3] æµ‹è¯•: {pdf['title'][:50]}...")

                pdf_response = session.head(pdf['url'], timeout=10)
                print(f"   ğŸ“¡ çŠ¶æ€ç : {pdf_response.status_code}")

                if pdf_response.status_code == 200:
                    accessible_count += 1
                    print(f"   âœ… å¯è®¿é—®")
                else:
                    print(f"   âŒ ä¸å¯è®¿é—®")

            except Exception as e:
                print(f"   âš ï¸  æµ‹è¯•å¤±è´¥: {str(e)}")

        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
        print(f"   æ€»ä¸­æ–‡PDFæ•°: {len(chinese_pdfs)}")
        print(f"   å¯è®¿é—®PDFæ•°: {accessible_count}/3 (æµ‹è¯•æ ·æœ¬)")

        # ä¸ç”¨æˆ·æåˆ°çš„13ä¸ªæ–‡ä»¶è¿›è¡Œå¯¹æ¯”
        expected_count = 13
        if len(chinese_pdfs) >= expected_count:
            print(f"\nâœ… æˆåŠŸï¼æ‰¾åˆ° {len(chinese_pdfs)} ä¸ªä¸­æ–‡PDF (æœŸæœ›: {expected_count})")
            return True
        else:
            print(f"\nâš ï¸  æ‰¾åˆ° {len(chinese_pdfs)} ä¸ªä¸­æ–‡PDF (æœŸæœ›: {expected_count})")
            print(f"   å¯èƒ½éœ€è¦æ£€æŸ¥è§£æé€»è¾‘")
            return len(chinese_pdfs) > 0

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_translation_page_parsing()

    print(f"\n{'='*60}")
    if success:
        print("ğŸ‰ ç¿»è¯‘é¡µé¢è§£ææµ‹è¯•æˆåŠŸï¼")
        print("âœ… ä¿®å¤åçš„åŒè¯­æ‚£è€…æŒ‡å—è§£æé€»è¾‘ç°åœ¨åº”è¯¥èƒ½å¤Ÿæ­£ç¡®å¤„ç†ä¸­æ–‡PDF")
        print("ğŸš€ å¯ä»¥å°è¯•è¿è¡Œä¸»ç¨‹åºä¸‹è½½åŒè¯­æ‚£è€…æŒ‡å—")
    else:
        print("âš ï¸  ç¿»è¯‘é¡µé¢è§£ææµ‹è¯•å¤±è´¥")
        print("ğŸ”§ éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•è§£æé€»è¾‘")