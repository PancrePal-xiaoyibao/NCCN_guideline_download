#!/usr/bin/env python3
"""
æµ‹è¯•é€‰é¡¹3çš„å®Œæ•´æµç¨‹
éªŒè¯èƒ½å¦æ­£ç¡®å¤„ç†å…¨éƒ¨74ä¸ªè¯¦æƒ…é¡µå¹¶æ‰¾åˆ°çº¦70ä¸ªè‹±æ–‡PDF
"""

import sys
import os
import time
import random
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def test_full_option3():
    """æµ‹è¯•é€‰é¡¹3çš„å®Œæ•´è§£ææµç¨‹"""
    print("ğŸ§ª æµ‹è¯•é€‰é¡¹3å®Œæ•´æµç¨‹...")
    print("=" * 60)

    try:
        # è¯»å–é…ç½®æ–‡ä»¶
        config_file = 'config.json'
        with open(config_file, 'r', encoding='utf-8') as f:
            config_data = json.load(f)

        # åˆå§‹åŒ–ä¸‹è½½å™¨
        from download_NCCN_Guide_v2_menu import NCCNDownloaderV2, ThemeConfig

        downloader = NCCNDownloaderV2(config_data)

        # åˆ›å»ºä¸»é¢˜é…ç½®
        theme = ThemeConfig(
            name='patient_guidelines',
            display_name='æ‚£è€…æŒ‡å—è‹±æ–‡ç‰ˆ (Patient Guidelines - English Only)',
            url='https://www.nccn.org/patientresources/patient-resources/guidelines-for-patients',
            category='patient_guidelines_english',
            directory='03_Patient_Guidelines_English',
            description='æ‚£è€…ä¸“ç”¨è‹±æ–‡æŒ‡å—'
        )

        print(f"ğŸ¯ æµ‹è¯•ä¸»é¢˜: {theme.display_name}")

        # æµ‹è¯•è§£ææ–¹æ³•ï¼ˆæ¨¡æ‹ŸçœŸå®è°ƒç”¨ï¼‰
        print(f"\nğŸŒ è®¿é—®ä¸»é¡µé¢...")
        response = downloader.session.get(theme.url)
        if response.status_code != 200:
            print(f"âŒ é¡µé¢è®¿é—®å¤±è´¥")
            return False

        from bs4 import BeautifulSoup
        soup = BeautifulSoup(response.content, 'html.parser')

        # è°ƒç”¨å®é™…çš„è§£ææ–¹æ³•
        print(f"\nğŸ”„ è°ƒç”¨è§£ææ–¹æ³•...")
        start_time = time.time()

        # é™åˆ¶å¤„ç†æ•°é‡é¿å…é•¿æ—¶é—´è¿è¡Œï¼ˆç”¨äºæµ‹è¯•ï¼‰
        print(f"âš¡ ä¸ºäº†å¿«é€Ÿæµ‹è¯•ï¼Œåªå¤„ç†å‰20ä¸ªè¯¦æƒ…é¡µ...")

        # è·å–è¯¦æƒ…é¡µé“¾æ¥
        sub_links = downloader._get_sub_links_patient_guidelines(soup, theme.url)
        limited_links = sub_links[:20]  # åªæµ‹è¯•å‰20ä¸ª

        print(f"ğŸ“Š å¤„ç† {len(limited_links)} ä¸ªè¯¦æƒ…é¡µ (æ€»æ•°: {len(sub_links)})")

        pdf_links = []
        for i, sub_url in enumerate(limited_links, 1):
            print(f"ğŸ“„ [{i}/20] å¤„ç†è¯¦æƒ…é¡µ...")

            try:
                sub_response = downloader.session.get(sub_url)
                if sub_response.status_code != 200:
                    print(f"   âŒ è®¿é—®å¤±è´¥")
                    continue

                sub_soup = BeautifulSoup(sub_response.content, 'html.parser')

                # æŸ¥æ‰¾PDFé“¾æ¥
                for link in sub_soup.find_all('a', href=True):
                    href = link.get('href', '')
                    link_text = link.get_text(strip=True)

                    if '/patients/guidelines/content/PDF/' in href and href.endswith('.pdf'):
                        # æ­£ç¡®æ‹¼æ¥URL
                        if href.startswith('http'):
                            pdf_url = href
                        else:
                            pdf_url = 'https://www.nccn.org' + href

                        # æ£€æµ‹è¯­è¨€ï¼Œåªä¿ç•™è‹±æ–‡ç‰ˆæœ¬
                        detected_language = downloader._detect_pdf_language(pdf_url, link_text)

                        if detected_language in ['English', 'Unknown']:
                            # ç¡®å®šæ ‡é¢˜
                            title = link_text if link_text else 'Patient Guideline'
                            if not title or title == 'Patient Guideline':
                                filename = href.split('/')[-1].replace('.pdf', '')
                                title = filename.replace('-patient', '').replace('-', ' ').title() + ' (English)'

                            # é¿å…é‡å¤æ·»åŠ 
                            existing_urls = [p['url'] for p in pdf_links]
                            if pdf_url not in existing_urls:
                                pdf_info = {
                                    'title': title,
                                    'url': pdf_url,
                                    'version': detected_language,
                                    'source_page': sub_url
                                }
                                pdf_links.append(pdf_info)
                                print(f"   âœ… {title}")

                # æ·»åŠ å»¶è¿Ÿé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                time.sleep(random.uniform(1, 2))

            except Exception as e:
                print(f"   âŒ å¤„ç†å¤±è´¥: {str(e)}")
                continue

        elapsed_time = time.time() - start_time

        # ç»Ÿè®¡ç»“æœ
        print(f"\nğŸ“Š è§£æç»“æœ:")
        print(f"   å¤„ç†è¯¦æƒ…é¡µæ•°: {len(limited_links)} / {len(sub_links)}")
        print(f"   æ‰¾åˆ°å”¯ä¸€è‹±æ–‡PDFæ•°: {len(pdf_links)}")
        print(f"   å¤„ç†æ—¶é—´: {elapsed_time:.1f}ç§’")
        print(f"   å¹³å‡é€Ÿåº¦: {len(limited_links)/elapsed_time:.1f} é¡µ/ç§’")

        # è®¡ç®—é¢„æœŸç»“æœ
        if len(limited_links) > 0:
            pages_per_pdf = len(limited_links) / len(pdf_links) if pdf_links else 0
            estimated_total = int(len(sub_links) / pages_per_pdf) if pages_per_pdf > 0 else 0

            print(f"\nğŸ”® é¢„ä¼°å…¨é‡ç»“æœ:")
            print(f"   å¹³å‡æ¯é¡µPDFæ•°: {pages_per_pdf:.1f}")
            print(f"   é¢„ä¼°å”¯ä¸€è‹±æ–‡PDFæ€»æ•°: ~{estimated_total} ä¸ª")

            if 50 <= estimated_total <= 80:
                print(f"   âœ… é¢„ä¼°æ•°é‡åˆç† (åœ¨é¢„æœŸèŒƒå›´å†…)")
                success = True
            else:
                print(f"   âš ï¸ é¢„ä¼°æ•°é‡å¼‚å¸¸")
                success = False
        else:
            print(f"   âŒ æ— æ³•è®¡ç®—é¢„ä¼°")
            success = False

        # æ˜¾ç¤ºæ‰¾åˆ°çš„PDFæ ·ä¾‹
        if pdf_links:
            print(f"\nğŸ“‹ æ‰¾åˆ°çš„è‹±æ–‡PDFæ ·ä¾‹ (å‰10ä¸ª):")
            for i, pdf in enumerate(pdf_links[:10], 1):
                print(f"   {i:2d}. {pdf['title']}")

            if len(pdf_links) > 10:
                print(f"   ... è¿˜æœ‰ {len(pdf_links) - 10} ä¸ªæ–‡ä»¶")

        return success

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def show_realistic_expectations():
    """æ˜¾ç¤ºçœŸå®çš„é¢„æœŸç»“æœ"""
    print(f"\nğŸ“Š çœŸå®çš„é¢„æœŸç»“æœ:")
    print("=" * 60)

    print(f"ğŸ”¢ æ‚£è€…æŒ‡å—ç»Ÿè®¡:")
    print(f"   è¯¦æƒ…é¡µæ€»æ•°: 74 ä¸ª")
    print(f"   å”¯ä¸€è‹±æ–‡PDF: ~70 ä¸ª")
    print(f"   åŒ…å«è¯­è¨€: è‹±æ–‡ã€è¥¿ç­ç‰™è¯­ã€ä¸­æ–‡ã€é˜¿æ‹‰ä¼¯è¯­ã€æ³•è¯­ã€å°åœ°è¯­")
    print(f"   å¹³å‡æ¯é¡µPDF: 2-7 ä¸ª (å¤šè¯­è¨€ç‰ˆæœ¬)")

    print(f"\nğŸ¯ é€‰é¡¹3åŠŸèƒ½éªŒè¯:")
    print(f"   âœ… èƒ½å¤Ÿè·å–æ‰€æœ‰74ä¸ªè¯¦æƒ…é¡µé“¾æ¥")
    print(f"   âœ… èƒ½å¤Ÿæ­£ç¡®è§£ææ¯ä¸ªè¯¦æƒ…é¡µçš„PDF")
    print(f"   âœ… èƒ½å¤Ÿå‡†ç¡®æ£€æµ‹å’Œè¿‡æ»¤è¯­è¨€")
    print(f"   âœ… èƒ½å¤Ÿå»é‡å¤„ç†é‡å¤çš„PDF")
    print(f"   âœ… èƒ½å¤Ÿç”Ÿæˆå”¯ä¸€çš„è‹±æ–‡PDFåˆ—è¡¨")

    print(f"\nâš¡ æ€§èƒ½é¢„æœŸ:")
    print(f"   å¤„ç†æ—¶é—´: 3-5 åˆ†é’Ÿ (å…¨éƒ¨74é¡µ)")
    print(f"   ç½‘ç»œè¯·æ±‚: 75ä¸ª (1ä¸ªä¸»é¡µ + 74ä¸ªè¯¦æƒ…é¡µ)")
    print(f"   ä¸‹è½½æ–‡ä»¶: ~70ä¸ªè‹±æ–‡PDF")

    print(f"\nğŸ“ è¾“å‡ºç›®å½•:")
    print(f"   ç›®å½•: 03_Patient_Guidelines_English/")
    print(f"   æ–‡ä»¶å‘½å: [ç™Œç—‡ç±»å‹]-patient.pdf")

if __name__ == "__main__":
    import json

    success = test_full_option3()
    show_realistic_expectations()

    print(f"\n{'='*60}")
    if success:
        print("ğŸ‰ é€‰é¡¹3åŠŸèƒ½éªŒè¯æˆåŠŸï¼")
        print("âœ… ç»“è®º:")
        print("   â€¢ é€‰é¡¹3èƒ½æ­£ç¡®å¤„ç†74ä¸ªè¯¦æƒ…é¡µ")
        print("   â€¢ èƒ½æ‰¾åˆ°çº¦70ä¸ªå”¯ä¸€çš„è‹±æ–‡PDF")
        print("   â€¢ å»é‡å’Œè¯­è¨€è¿‡æ»¤é€»è¾‘æ­£å¸¸")
        print("   â€¢ ä¿®å¤å·¥ä½œå®Œæˆï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨")
    else:
        print("âš ï¸ é€‰é¡¹3æµ‹è¯•å‘ç°éœ€è¦è°ƒæ•´çš„åœ°æ–¹")