#!/usr/bin/env python3
"""
è¯¦ç»†è°ƒè¯•é€‰é¡¹3çš„PDFè§£æè¿‡ç¨‹
æ£€æŸ¥ä¸ºä»€ä¹ˆåªæ‰¾åˆ°10ä¸ªPDFè€Œä¸æ˜¯é¢„æœŸçš„60+
"""

import sys
import os
import time
import random
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def debug_option3_detailed():
    """è¯¦ç»†è°ƒè¯•é€‰é¡¹3çš„PDFè§£æè¿‡ç¨‹"""
    print("ğŸ” è¯¦ç»†è°ƒè¯•é€‰é¡¹3PDFè§£æè¿‡ç¨‹...")
    print("=" * 60)

    try:
        # è¯»å–é…ç½®æ–‡ä»¶
        config_file = 'config.json'
        with open(config_file, 'r', encoding='utf-8') as f:
            config_data = json.load(f)

        # åˆå§‹åŒ–ä¸‹è½½å™¨
        from download_NCCN_Guide_v2_menu import NCCNDownloaderV2, ThemeConfig

        downloader = NCCNDownloaderV2(config_data)

        # åˆ›å»ºä¸»é¢˜é…ç½®
        theme = ThemeConfig(
            name='patient_guidelines',
            display_name='æ‚£è€…æŒ‡å—è‹±æ–‡ç‰ˆ (Patient Guidelines - English Only)',
            url='https://www.nccn.org/patientresources/patient-resources/guidelines-for-patients',
            category='patient_guidelines_english',
            directory='03_Patient_Guidelines_English',
            description='æ‚£è€…ä¸“ç”¨è‹±æ–‡æŒ‡å—'
        )

        print(f"ğŸ¯ è°ƒè¯•ä¸»é¢˜: {theme.display_name}")

        # è®¿é—®ä¸»é¡µé¢
        print(f"\nğŸŒ è®¿é—®ä¸»é¡µé¢...")
        response = downloader.session.get(theme.url)
        if response.status_code != 200:
            print(f"âŒ é¡µé¢è®¿é—®å¤±è´¥")
            return

        from bs4 import BeautifulSoup
        soup = BeautifulSoup(response.content, 'html.parser')

        # è·å–è¯¦æƒ…é¡µé“¾æ¥
        print(f"\nğŸ” è·å–è¯¦æƒ…é¡µé“¾æ¥...")
        sub_links = downloader._get_sub_links_patient_guidelines(soup, theme.url)
        print(f"ğŸ“Š æ€»å…±æ‰¾åˆ° {len(sub_links)} ä¸ªè¯¦æƒ…é¡µé“¾æ¥")

        # æµ‹è¯•å‰3ä¸ªè¯¦æƒ…é¡µçš„è¯¦ç»†è§£æè¿‡ç¨‹
        test_links = sub_links[:3]
        print(f"\nğŸ§ª è¯¦ç»†åˆ†æå‰3ä¸ªè¯¦æƒ…é¡µçš„PDFè§£æè¿‡ç¨‹...")

        total_pdfs = 0
        english_pdfs = 0
        detailed_results = []

        for i, sub_url in enumerate(test_links, 1):
            print(f"\nğŸ“„ [{i}/3] è¯¦ç»†åˆ†æè¯¦æƒ…é¡µ:")
            print(f"   URL: {sub_url}")

            try:
                sub_response = downloader.session.get(sub_url)
                if sub_response.status_code != 200:
                    print(f"   âŒ è®¿é—®å¤±è´¥")
                    continue

                sub_soup = BeautifulSoup(sub_response.content, 'html.parser')

                # æŸ¥æ‰¾æ‰€æœ‰PDFé“¾æ¥å¹¶è¯¦ç»†åˆ†æ
                all_pdf_links = []
                for link in sub_soup.find_all('a', href=True):
                    href = link.get('href', '')
                    link_text = link.get_text(strip=True)

                    if '/patients/guidelines/content/PDF/' in href and href.endswith('.pdf'):
                        all_pdf_links.append({
                            'href': href,
                            'text': link_text,
                            'full_url': 'https://www.nccn.org' + href if not href.startswith('http') else href
                        })

                print(f"   ğŸ“‹ æ‰¾åˆ° {len(all_pdf_links)} ä¸ªPDFé“¾æ¥:")
                page_english_count = 0

                for j, pdf_info in enumerate(all_pdf_links, 1):
                    # è¯¦ç»†æ£€æµ‹è¯­è¨€
                    detected_lang = downloader._detect_pdf_language(pdf_info['href'], pdf_info['text'])
                    title = pdf_info['text'] if pdf_info['text'] else 'æ— æ ‡é¢˜'
                    print(f"      {j}. {title}")
                    print(f"         URL: {pdf_info['href']}")
                    print(f"         æ£€æµ‹è¯­è¨€: {detected_lang}")

                    if detected_lang in ['English', 'Unknown']:
                        page_english_count += 1
                        detailed_results.append({
                            'page': i,
                            'title': title,
                            'url': pdf_info['href'],
                            'full_url': pdf_info['full_url'],
                            'language': detected_lang
                        })

                print(f"   âœ… é¡µé¢è‹±æ–‡PDFæ•°: {page_english_count}")
                total_pdfs += len(all_pdf_links)
                english_pdfs += page_english_count

            except Exception as e:
                print(f"   âŒ å¤„ç†å¤±è´¥: {str(e)}")
                continue

        print(f"\nğŸ“Š åˆæ­¥ç»Ÿè®¡ç»“æœ:")
        print(f"   æµ‹è¯•è¯¦æƒ…é¡µæ•°: {len(test_links)}")
        print(f"   æ€»PDFé“¾æ¥æ•°: {total_pdfs}")
        print(f"   è‹±æ–‡PDFæ•°: {english_pdfs}")
        print(f"   æ¯”ä¾‹: {english_pdfs}/{total_pdfs} = {english_pdfs/total_pdfs*100:.1f}%")

        # åˆ†æé—®é¢˜
        print(f"\nğŸ” é—®é¢˜åˆ†æ:")

        if total_pdfs == 0:
            print(f"   âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•PDFé“¾æ¥")
            print(f"   ğŸ”§ å¯èƒ½åŸå› :")
            print(f"      - é¡µé¢ç»“æ„å·²å˜åŒ–")
            print(f"      - é“¾æ¥é€‰æ‹©å™¨ä¸æ­£ç¡®")
            print(f"      - éœ€è¦ç™»å½•æ‰èƒ½è®¿é—®")
        else:
            non_english_count = total_pdfs - english_pdfs
            if non_english_count > 0:
                print(f"   âš ï¸ æ‰¾åˆ° {non_english_count} ä¸ªéè‹±æ–‡PDFè¢«è¿‡æ»¤")
                print(f"   ğŸ”§ å¯èƒ½åŸå› :")
                print(f"      - è¯­è¨€æ£€æµ‹é€»è¾‘è¿‡äºä¸¥æ ¼")
                print(f"      - åŒ…å«è¥¿ç­ç‰™è¯­ã€ä¸­æ–‡ç­‰ç‰ˆæœ¬")
                print(f"      - URLæ ¼å¼ä¸ç¬¦åˆé¢„æœŸ")

            if english_pdfs == 0:
                print(f"   âŒ æ‰€æœ‰PDFéƒ½è¢«è¿‡æ»¤æ‰äº†")
                print(f"   ğŸ”§ å¯èƒ½åŸå› :")
                print(f"      - è¯­è¨€æ£€æµ‹é€»è¾‘æœ‰è¯¯")
                print(f"      - æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯éè‹±æ–‡")
                print(f"      - æ£€æµ‹æ¡ä»¶è¿‡äºä¸¥æ ¼")

        # æ£€æŸ¥è¯­è¨€æ£€æµ‹é€»è¾‘
        print(f"\nğŸ§ª æµ‹è¯•è¯­è¨€æ£€æµ‹é€»è¾‘...")
        test_urls = [
            'https://www.nccn.org/patients/guidelines/content/PDF/all-patient.pdf',
            'https://www.nccn.org/patients/guidelines/content/PDF/ALL-es-patient.pdf',
            'https://www.nccn.org/patients/guidelines/content/PDF/Bladder-zh-patient.pdf',
        ]

        for test_url in test_urls:
            detected = downloader._detect_pdf_language(test_url, '')
            print(f"   {test_url} â†’ {detected}")

        # ç»™å‡ºä¿®å¤å»ºè®®
        print(f"\nğŸ’¡ ä¿®å¤å»ºè®®:")

        if english_pdfs < total_pdfs * 0.5:  # å¦‚æœè‹±æ–‡PDFå°‘äº50%
            print(f"   1. æ”¾å®½è¯­è¨€æ£€æµ‹æ¡ä»¶")
            print(f"   2. æ£€æŸ¥é»˜è®¤å¤„ç†é€»è¾‘")
            print(f"   3. è€ƒè™‘å°†Unknownè§†ä¸ºè‹±æ–‡")

        if total_pdfs < len(test_links) * 2:  # å¦‚æœå¹³å‡æ¯ä¸ªé¡µé¢PDFå°‘äº2ä¸ª
            print(f"   1. æ£€æŸ¥PDFé“¾æ¥é€‰æ‹©å™¨")
            print(f"   2. éªŒè¯é¡µé¢ç»“æ„")
            print(f"   3. æ£€æŸ¥æ˜¯å¦æœ‰åŠ¨æ€åŠ è½½å†…å®¹")

        print(f"\nğŸ“‹ è¯¦ç»†è§£æçš„è‹±æ–‡PDF:")
        for result in detailed_results:
            print(f"   {result['title']} â†’ {result['language']}")

    except Exception as e:
        print(f"âŒ è°ƒè¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    import json

    debug_option3_detailed()