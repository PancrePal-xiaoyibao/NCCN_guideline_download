#!/usr/bin/env python3
"""
æœ€ç»ˆæµ‹è¯•ï¼šéªŒè¯ä¿®å¤åçš„ç¿»è¯‘é¡µé¢è§£æé€»è¾‘æ˜¯å¦èƒ½æ‰¾åˆ°å…¨éƒ¨13ä¸ªä¸­æ–‡PDF
"""

import sys
import os
from pathlib import Path
from bs4 import BeautifulSoup
import requests

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def test_final_fix():
    """æµ‹è¯•ä¿®å¤åçš„ç¿»è¯‘é¡µé¢è§£æé€»è¾‘"""
    print("ğŸ§ª æœ€ç»ˆæµ‹è¯•ï¼šéªŒè¯ä¿®å¤åçš„ç¿»è¯‘é¡µé¢è§£æé€»è¾‘...")
    print("=" * 60)

    try:
        # è¯»å–Cookie
        with open('extracted_cookies.txt', 'r', encoding='utf-8') as f:
            cookie_string = f.read().strip()

        # è§£æCookie
        cookies = {}
        for item in cookie_string.split(';'):
            if '=' in item:
                key, value = item.strip().split('=', 1)
                cookies[key] = value

        # åˆ›å»ºsession
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })
        session.cookies.update(cookies)

        # è®¿é—®ç¿»è¯‘é¡µé¢
        translation_url = "https://www.nccn.org/global/what-we-do/guidelines-for-patients-translations"
        print(f"ğŸŒ è®¿é—®ç¿»è¯‘é¡µé¢: {translation_url}")

        response = session.get(translation_url)
        print(f"ğŸ“¡ çŠ¶æ€ç : {response.status_code}")

        if response.status_code != 200:
            print("âŒ ç¿»è¯‘é¡µé¢è®¿é—®å¤±è´¥")
            return False

        # è§£æHTML
        translation_soup = BeautifulSoup(response.content, 'html.parser')

        # æ¨¡æ‹Ÿä¿®å¤åçš„æ­¥éª¤3é€»è¾‘
        print(f"\nğŸ” æ¨¡æ‹Ÿä¿®å¤åçš„æ­¥éª¤3: è§£æChinese Translationséƒ¨åˆ†...")

        # æŸ¥æ‰¾Chinese Translationséƒ¨åˆ†
        chinese_headers = translation_soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])

        chinese_section = None
        for header in chinese_headers:
            if 'Chinese' in header.get_text():
                chinese_section = header
                print(f"âœ… æ‰¾åˆ°Chinese Translationséƒ¨åˆ†: {header.get_text(strip=True)}")
                break

        if not chinese_section:
            print("âŒ æœªæ‰¾åˆ°Chinese Translationséƒ¨åˆ†")
            return False

        # ä»Chinese Translationséƒ¨åˆ†å¼€å§‹æŸ¥æ‰¾PDFé“¾æ¥
        current = chinese_section
        processed_sections = 0
        chinese_pdfs = []

        # éå†Chinese Translationsåé¢çš„æ‰€æœ‰å…ƒç´ ï¼Œç›´åˆ°ä¸‹ä¸€ä¸ªè¯­è¨€æ ‡é¢˜
        while current and processed_sections < 50:
            current = current.find_next_sibling()

            if current is None:
                break

            if current.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:  # é‡åˆ°ä¸‹ä¸€ä¸ªè¯­è¨€éƒ¨åˆ†ï¼Œåœæ­¢
                print(f"ğŸ›‘ é‡åˆ°ä¸‹ä¸€ä¸ªè¯­è¨€éƒ¨åˆ†: {current.get_text(strip=True)[:50]}...")
                break

            # æŸ¥æ‰¾å½“å‰å…ƒç´ ä¸­çš„æ‰€æœ‰é“¾æ¥
            links = current.find_all('a', href=True)

            for link in links:
                href = link.get('href', '')
                link_text = link.get_text(strip=True)

                # æŸ¥æ‰¾PDFé“¾æ¥
                if '/patients/guidelines/content/PDF/' in href and href.endswith('.pdf'):
                    # æ­£ç¡®æ‹¼æ¥URL
                    if href.startswith('http'):
                        pdf_url = href
                    else:
                        pdf_url = 'https://www.nccn.org' + href

                    # ç¡®å®šæ ‡é¢˜
                    title = link_text if link_text else 'Chinese Patient Guideline'
                    if not title:
                        filename = href.split('/')[-1].replace('.pdf', '')
                        title = filename.replace('-zh', '').replace('-', ' ') + ' (Chinese)'

                    chinese_pdfs.append({
                        'title': title,
                        'url': pdf_url,
                        'href': href
                    })

                    print(f"ğŸ‡¨ğŸ‡³ æ‰¾åˆ°PDF: {title}")
                    print(f"   æ–‡ä»¶: {href}")

            processed_sections += 1

        print(f"\nâœ… ä¿®å¤åçš„è§£æç»“æœ:")
        print(f"   æ€»å…±æ‰¾åˆ° {len(chinese_pdfs)} ä¸ªä¸­æ–‡PDF")

        # éªŒè¯ç»“æœ
        if len(chinese_pdfs) >= 10:  # ä¸æœŸæœ›çš„13ä¸ªæ¥è¿‘
            print(f"\nğŸ‰ æµ‹è¯•æˆåŠŸï¼")
            print(f"âœ… ä¿®å¤åçš„åŒè¯­æ‚£è€…æŒ‡å—è§£æç°åœ¨åº”è¯¥èƒ½æ­£ç¡®å¤„ç†ä¸­æ–‡PDF")
            print(f"ğŸ“‹ æ‰€æœ‰æ‰¾åˆ°çš„ä¸­æ–‡PDF:")
            for i, pdf in enumerate(chinese_pdfs, 1):
                print(f"   {i:2d}. {pdf['title']}")

            return True
        else:
            print(f"\nâš ï¸  æµ‹è¯•å¤±è´¥ï¼Œåªæ‰¾åˆ° {len(chinese_pdfs)} ä¸ªä¸­æ–‡PDF")
            print(f"   æœŸæœ›æ‰¾åˆ°13ä¸ªä¸­æ–‡PDF")
            return False

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_final_fix()

    print(f"\n{'='*60}")
    if success:
        print("ğŸ‰ æœ€ç»ˆä¿®å¤éªŒè¯æˆåŠŸï¼")
        print("âœ… åŒè¯­æ‚£è€…æŒ‡å—è§£æé€»è¾‘ç°åœ¨åº”è¯¥èƒ½å¤Ÿ:")
        print("   â€¢ æ‰¾åˆ°Chinese Translationséƒ¨åˆ†")
        print("   â€¢ æå–å…¨éƒ¨13ä¸ªä¸­æ–‡PDF")
        print("   â€¢ åº”ç”¨æ­£ç¡®çš„è¯­è¨€è¿‡æ»¤")
        print("ğŸš€ ç°åœ¨å¯ä»¥æµ‹è¯•ä¸»ç¨‹åºé€‰é¡¹6")
    else:
        print("âš ï¸  æœ€ç»ˆä¿®å¤éªŒè¯å¤±è´¥")
        print("ğŸ”§ éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")